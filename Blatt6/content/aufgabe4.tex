\newpage
\section{Aufgabe4}
\label{sec:a4}

\subsection{a)}
\label{subsec:a4a}
1.) Tokenisierung: Segmentierung eines Textes in Einheiten, z.b. einzelne Wörter oder Satzteile.
    Das Ziel ist die Entfernung von unwichtigen Tokens, z.B. Füllwörtern oder Satzzeichen.\\
2.) Fehlerhafte Daten entfernen: Wenn sich Ausreißer unter den Daten befinden, z.B. Gewicht von 400kg bei Menschen.\\
3.) Default Werte verenden: es werden Default Werte anstelle der Fehlerhaften Daten verwendet.\\
4.) Ableiten aus Anderen Daten: aus Daten können korrekte Werte abgeleitet werden (Anrede aus Vornamen)\\
\subsection{b)}
\label{subsec:a4b}
 Es ist günstig Attribute auf einen einheitlichen Wertebereich zu normieren, für eine leichtere Weiterverarbeitung.
 (Z.B: Firmenzusatz: e.Kfr, e.Kfm zusammengefasst zu e.K)

\subsection{c)}
\label{subsec:a4c}
Lücken in den Datensätzen müssen sinnvoll ersetzt oder evtl. gelöscht werden.

\subsection{d)}
\label{subsec:a4d}
Beim Zusammenführen von Datensätzen muss beachtet werden, dass die Teile zueinander passen und kombiniert werden können.
